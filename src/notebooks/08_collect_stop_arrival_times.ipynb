{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "administrative-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "id": "separate-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import LineString\n",
    "from shapely.geometry import MultiLineString\n",
    "import numpy as np\n",
    "import numpy as npm\n",
    "import osmnx as ox\n",
    "import math\n",
    "import pandas as pd\n",
    "from shapely.ops import snap\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1369,
   "id": "congressional-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_speed_df_cache = {}\n",
    "avg_speed_attr_dict_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "id": "tested-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRS_LATLON = 'EPSG:4326'\n",
    "DATA_DIR = '../../data'\n",
    "EXPORTS_DIR = f'{DATA_DIR}/exports'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "id": "perfect-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peek(df):\n",
    "    print(len(df))\n",
    "    display(df.iloc[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "id": "three-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_stop_sequence_dict = {}\n",
    "with open(f'{EXPORTS_DIR}/json/manhattan/trip_stop_sequence_dict.json', 'r') as fp:\n",
    "    trip_stop_sequence_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1373,
   "id": "provincial-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_manifest = {}\n",
    "with open(f'{EXPORTS_DIR}/json/manhattan/trip_manifest.json', 'r') as fp:\n",
    "    trip_manifest = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "id": "familiar-conviction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505068\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>pickup_type</th>\n",
       "      <th>drop_off_type</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>shape_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OF_C1-Weekday-033500_M1_101</td>\n",
       "      <td>05:35:00</td>\n",
       "      <td>05:35:00</td>\n",
       "      <td>400001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HARLEM 147 ST via MADISON AV</td>\n",
       "      <td>M010006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OF_C1-Weekday-033500_M1_101</td>\n",
       "      <td>05:35:36</td>\n",
       "      <td>05:35:36</td>\n",
       "      <td>400002</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HARLEM 147 ST via MADISON AV</td>\n",
       "      <td>M010006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OF_C1-Weekday-033500_M1_101</td>\n",
       "      <td>05:36:14</td>\n",
       "      <td>05:36:14</td>\n",
       "      <td>400003</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HARLEM 147 ST via MADISON AV</td>\n",
       "      <td>M010006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       trip_id arrival_time departure_time  stop_id  \\\n",
       "0  OF_C1-Weekday-033500_M1_101     05:35:00       05:35:00   400001   \n",
       "1  OF_C1-Weekday-033500_M1_101     05:35:36       05:35:36   400002   \n",
       "2  OF_C1-Weekday-033500_M1_101     05:36:14       05:36:14   400003   \n",
       "\n",
       "   stop_sequence  pickup_type  drop_off_type                 trip_headsign  \\\n",
       "0              1            0              0  HARLEM 147 ST via MADISON AV   \n",
       "1              2            0              0  HARLEM 147 ST via MADISON AV   \n",
       "2              3            0              0  HARLEM 147 ST via MADISON AV   \n",
       "\n",
       "  shape_id  \n",
       "0  M010006  \n",
       "1  M010006  \n",
       "2  M010006  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timetable_df = pd.read_csv(f'{EXPORTS_DIR}/csv/manhattan/timetable.csv')\n",
    "peek(timetable_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "id": "elder-artist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>M1_0</th>\n",
       "      <th>M1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400001</th>\n",
       "      <td>4 AV/E 10 ST</td>\n",
       "      <td>40.731342</td>\n",
       "      <td>-73.990292</td>\n",
       "      <td>POINT (-73.99240 40.73060)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400002</th>\n",
       "      <td>4 AV/E 12 ST</td>\n",
       "      <td>40.732608</td>\n",
       "      <td>-73.989958</td>\n",
       "      <td>POINT (-73.99240 40.73060)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400003</th>\n",
       "      <td>4 AV/E 13 ST</td>\n",
       "      <td>40.733936</td>\n",
       "      <td>-73.989720</td>\n",
       "      <td>POINT (-73.99240 40.73060)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            stop_name   stop_lat   stop_lon                        M1_0 M1_1\n",
       "stop_id                                                                     \n",
       "400001   4 AV/E 10 ST  40.731342 -73.990292  POINT (-73.99240 40.73060)  NaN\n",
       "400002   4 AV/E 12 ST  40.732608 -73.989958  POINT (-73.99240 40.73060)  NaN\n",
       "400003   4 AV/E 13 ST  40.733936 -73.989720  POINT (-73.99240 40.73060)  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stops_nodes_df = pd.read_csv(f'{EXPORTS_DIR}/csv/manhattan/stops_nodes.csv')\n",
    "stops_nodes_df = stops_nodes_df.set_index('stop_id')\n",
    "peek(stops_nodes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "id": "handy-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_ids = list(stops_nodes_df.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "id": "transsexual-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "\n",
    "route_gdfs = []\n",
    "\n",
    "for route_id in route_ids:\n",
    "    route_df = stops_nodes_df[~stops_nodes_df[route_id].isna()]\n",
    "    route_df[route_id] = route_df[route_id].apply(wkt.loads)\n",
    "    route_df = route_df[[route_id]]\n",
    "    route_gdf = gpd.GeoDataFrame(route_df, geometry=route_df[route_id], crs=CRS_LATLON)\n",
    "    route_gdfs.append(route_gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "id": "imposed-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(row):\n",
    "    if row['last_geometry'] is None:\n",
    "        return None\n",
    "    # Approx degrees to meters\n",
    "    return row['geometry'].distance(row['last_geometry']) * (0.11 / 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "id": "blessed-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_df(trip_key, route_id):\n",
    "    sequence_key = trip_key[-1]\n",
    "    sequence = trip_stop_sequence_dict[trip_key]\n",
    "    \n",
    "    sequence_df = pd.DataFrame({'stop_id': sequence})\n",
    "    sequence_df = sequence_df.set_index('stop_id')\n",
    "\n",
    "    route_index = route_ids.index(route_id)\n",
    "    route_gdf = route_gdfs[route_index]\n",
    "\n",
    "    sequence_df = sequence_df.merge(route_gdf, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    sequence_gdf = gpd.GeoDataFrame(sequence_df, crs=CRS_LATLON)\n",
    "    sequence_gdf = sequence_gdf[['geometry']]\n",
    "    \n",
    "    return sequence_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "id": "present-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_df(trip_key):\n",
    "    sequence_key = trip_key[-1]\n",
    "    sequence = trip_stop_sequence_dict[trip_key]\n",
    "    \n",
    "    sequence_df = pd.DataFrame({'stop_id': sequence})\n",
    "    sequence_df = sequence_df.set_index('stop_id')\n",
    "\n",
    "    route_index = route_ids.index(route_id)\n",
    "    route_gdf = route_gdfs[route_index]\n",
    "\n",
    "    sequence_df = sequence_df.merge(route_gdf, left_index=True, right_index=True, how='left')\n",
    "    sequence_df = sequence_df.drop(columns=[route_id])\n",
    "    \n",
    "    sequence_gdf = gpd.GeoDataFrame(sequence_df, crs=CRS_LATLON)\n",
    "    sequence_gdf['last_geometry'] = sequence_gdf['geometry'].shift()\n",
    "    sequence_gdf['distance'] = sequence_gdf.apply(lambda x: get_distance(x), axis=1)\n",
    "    sequence_gdf\n",
    "    \n",
    "    return sequence_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "id": "cardiovascular-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_manifest = {}\n",
    "with open(f'{EXPORTS_DIR}/json/manhattan/trip_manifest.json', 'r') as fp:\n",
    "    trip_manifest = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "id": "piano-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(row):\n",
    "    try:\n",
    "        start_time = row['last_time']\n",
    "        end_time = row['time']\n",
    "\n",
    "        if int(start_time[0:2]) > 23 or int(end_time[0:2]) > 23:\n",
    "            start_time = f'{int(start_time[0:2]) - 12}{start_time[2:]}'\n",
    "            end_time = f'{int(end_time[0:2]) - 12}{end_time[2:]}'\n",
    "    \n",
    "        return pd.Timedelta(pd.to_datetime(end_time, format='%H:%M:%S') - pd.to_datetime(start_time, format='%H:%M:%S')).seconds\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "id": "received-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_times_df(trip_id):\n",
    "    timetable_mi_df = timetable_df[timetable_df['trip_id'].str.contains(trip_id)]\n",
    "    timetable_mi_df = timetable_mi_df[timetable_mi_df['trip_id'].str.contains(f'_{route_id}_')]\n",
    "    timetable_mi_df = timetable_mi_df.set_index(['trip_id', 'stop_id'])\n",
    "    timetable_mi_df = timetable_mi_df.rename(columns={'arrival_time': 'time'})\n",
    "    \n",
    "    times_df = timetable_mi_df.loc[trip_id]\n",
    "    times_df['last_time'] = times_df['time'].shift()\n",
    "    times_df['duration'] = times_df.apply(lambda x: get_duration(x), axis=1)\n",
    "    times_df = times_df\n",
    "    return times_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "id": "conscious-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "route_mgs = []\n",
    "\n",
    "for route_id in route_ids:\n",
    "    route_mg = nx.read_graphml(f'{EXPORTS_DIR}/hybrid/manhattan/routes/{route_id}.graphml')\n",
    "    \n",
    "    g = nx.DiGraph()\n",
    "    edges = [(ast.literal_eval(e[0]), ast.literal_eval(e[1])) for e in route_mg.edges]\n",
    "    g.add_edges_from(edges)\n",
    "    g.graph['crs'] = CRS_LATLON\n",
    "    route_mgs.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "id": "horizontal-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_node_gdf(G):\n",
    "    \"\"\"Converts the given graph to a GeoDataFrame of its nodes.\"\"\"\n",
    "    nodes, data = zip(*G.nodes(data=True))\n",
    "    geom = [Point(node[0], node[1]) for node in nodes]\n",
    "    nodes_gdf = gpd.GeoDataFrame(data,\n",
    "                                 index=list(nodes),\n",
    "                                 crs=CRS_LATLON,\n",
    "                                 geometry=geom)\n",
    "    return nodes_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "id": "efficient-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_edge_gdf(G):\n",
    "    \"\"\"Converts the given graph to a GeoDataFrame of its edges.\"\"\"\n",
    "    u, v, data = zip(*G.edges(data=True))\n",
    "    edges = list(zip(u, v))\n",
    "    attrs = nx.get_edge_attributes(G, 'speed')\n",
    "    geom = [\n",
    "        LineString((Point(edge[0][0],\n",
    "                          edge[0][1]), Point(edge[1][0], edge[1][1])))\n",
    "        for edge in edges\n",
    "    ]\n",
    "    edge_index = [(edge[0] + edge[1]) for edge in edges]\n",
    "    edges_gdf = gpd.GeoDataFrame(data,\n",
    "                                 index=edge_index,\n",
    "                                 crs=CRS_LATLON,\n",
    "                                 geometry=list(geom))\n",
    "    edges_gdf['length'] = edges_gdf.geometry.length\n",
    "    edges_gdf = edges_gdf.drop(columns={\n",
    "        'route_shor',\n",
    "        'route_long',\n",
    "        'color',\n",
    "        'ShpName',\n",
    "        'Wkb',\n",
    "        'Wkt',\n",
    "        'Json',\n",
    "    }, errors='ignore')\n",
    "    return edges_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "id": "informative-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(mg, point):\n",
    "    threshold = 0.00001\n",
    "    for node in route_mg.nodes():\n",
    "        if abs(node[0] - point[0]) < threshold and abs(node[1] - point[1]) < threshold:\n",
    "            return node\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "id": "expanded-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trip_ids(trip_key):\n",
    "    route_id = trip_key.split(',')[0]\n",
    "    trip_id = trip_key.split(',')[1]\n",
    "    trip_keys = list(trip_manifest[trip_key])\n",
    "    trip_keys = [f for f in trip_keys if re.match(f'{trip_id}.*', f)]\n",
    "    trip_keys = [f for f in trip_keys if re.match(f'.*_{route_id}_', f)]\n",
    "    return trip_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "id": "typical-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = list(range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "id": "amino-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hour(x):\n",
    "    return int(math.floor((int(x[0:2]) % 24) / 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "id": "local-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speed_df(trip_id, point_df, times_df):\n",
    "    speed_df = times_df.merge(point_df, left_index=True, right_index=True, how='left')\n",
    "    speed_df = speed_df[['time', 'stop_sequence', 'geometry']]\n",
    "    speed_df = speed_df[speed_df['geometry'].notnull()]\n",
    "    speed_df = speed_df.sort_values(by=['stop_sequence'])\n",
    "    speed_df['last_time'] = speed_df['time'].shift()\n",
    "    speed_df['last_geometry'] = speed_df['geometry'].shift()\n",
    "    \n",
    "    if len(speed_df) == 0:\n",
    "        return None\n",
    "    \n",
    "    speed_df['distance'] = speed_df.apply(lambda x: get_distance(x), axis=1)\n",
    "    speed_df['duration'] = speed_df.apply(lambda x: get_duration(x), axis=1)\n",
    "    speed_df['speed'] = speed_df['distance'] / speed_df['duration']\n",
    "    speed_df = speed_df.drop(columns=['stop_sequence', 'last_time', 'distance', 'duration'])\n",
    "    speed_df = speed_df.dropna()\n",
    "    speed_df['hour'] = speed_df['time'].apply(lambda x: get_hour(x))\n",
    "    speed_df = speed_df.rename(columns={'last_geometry': 'start', 'geometry': 'end'})\n",
    "    return speed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "id": "sudden-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_speed_dfs(trip_key, route_id):\n",
    "    point_df = get_point_df(trip_key, route_id)\n",
    "    speed_dfs = []\n",
    "    errors = 0\n",
    "    \n",
    "    trip_ids = get_trip_ids(trip_key)\n",
    "\n",
    "    for trip_id in trip_ids:\n",
    "        times_df = get_times_df(trip_id)\n",
    "        speed_df = get_speed_df(trip_id, point_df, times_df)\n",
    "        if speed_df is None:\n",
    "            continue\n",
    "        \n",
    "        speed_df['start'] = speed_df['start'].apply(lambda x: x.wkt)\n",
    "        speed_df['end'] = speed_df['end'].apply(lambda x: x.wkt)\n",
    "        speed_df = speed_df.reset_index()\n",
    "        speed_df = speed_df.drop(columns=['stop_id'])\n",
    "        speed_df = speed_df.set_index(['start', 'end'])\n",
    "        speed_dfs.append(speed_df)\n",
    "        \n",
    "    avg_speed_dfs = []\n",
    "    \n",
    "    if len(speed_dfs) == 0:\n",
    "        raise Exception(f'{trip_key} produced no speed_dfs')\n",
    "    \n",
    "    for hour in hours:\n",
    "        hour_dfs = [df[df['hour'] == hour].drop(columns=['hour', 'time']) for df in speed_dfs]\n",
    "        \n",
    "        all_speed_dfs = hour_dfs[0].join(hour_dfs[1:], how='outer')\n",
    "        \n",
    "        avg_speed_df = pd.DataFrame(all_speed_dfs.mean(axis=1))\n",
    "        avg_speed_dfs.append(avg_speed_df)\n",
    "        \n",
    "    return avg_speed_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "id": "crucial-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_speed_attr_dict(avg_speed_dfs, route_mg):\n",
    "    attr_dict = {}\n",
    "    for hour, avg_speed_df in enumerate(avg_speed_dfs):\n",
    "        for row in avg_speed_df.iterrows():\n",
    "            index = row[0]\n",
    "            start, end = (wkt.loads(f) for f in index)\n",
    "            avg_speed = row[1][0]\n",
    "\n",
    "            start_node = get_node(route_mg, (start.x, start.y))\n",
    "            end_node = get_node(route_mg, (end.x, end.y))\n",
    "\n",
    "            try:\n",
    "                path = nx.shortest_path(route_mg, end_node, start_node)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            for i in range(len(path) - 1):\n",
    "                edge = (path[i], path[i+1])\n",
    "                if edge not in attr_dict:\n",
    "                    attr_dict[edge] = {}\n",
    "                key = f'speeds_{hour}'\n",
    "                if key not in attr_dict[edge]:\n",
    "                    attr_dict[edge][key] = []\n",
    "                attr_dict[edge][key].append(avg_speed)\n",
    "                \n",
    "        print(hour, len(avg_speed_df))\n",
    "        \n",
    "    return attr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "id": "irish-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(trip_stop_sequence_dict.keys())\n",
    "#del avg_speed_df_cache['M3,MV_C1-Weekday,1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "id": "fluid-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_keys = [\n",
    "    'M1,OF_C1-Weekday,0',\n",
    "    'M1,OF_C1-Weekday,1',\n",
    "    #'M2,MV_C1-Weekday,0',\n",
    "    #'M2,MV_C1-Weekday,1',\n",
    "    #'M3,MV_C1-Weekday,0',\n",
    "    #'M3,MV_C1-Weekday,1',\n",
    "    #'M4,MV_C1-Weekday,0',\n",
    "    #'M4,MV_C1-Weekday,1',\n",
    "    #'M57,MQ_C1-Weekday,0',\n",
    "    #'M57,MQ_C1-Weekday,1',\n",
    "    #'M1,OF_C1-Weekday,0',\n",
    "    #'M1,OF_C1-Weekday,1',\n",
    "    #'M2,MV_C1-Weekday,0',\n",
    "    #'M2,MV_C1-Weekday,1',\n",
    "    #'M3,MV_C1-Weekday,0',\n",
    "    #'M3,MV_C1-Weekday,1',\n",
    "    #'M4,MV_C1-Weekday,0',\n",
    "    #'M4,MV_C1-Weekday,1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "id": "buried-typing",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1421-1762dba30a2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mroute_mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroute_mgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroute_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mavg_speed_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_avg_speed_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrip_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mavg_speed_attr_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_avg_speed_attr_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_speed_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroute_mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1406-9d2ff02e8681>\u001b[0m in \u001b[0;36mget_avg_speed_dfs\u001b[0;34m(trip_key, route_id)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mhour_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hour'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhour\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hour'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspeed_dfs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mall_speed_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhour_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhour_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mavg_speed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_speed_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlc/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   8106\u001b[0m         \"\"\"\n\u001b[1;32m   8107\u001b[0m         return self._join_compat(\n\u001b[0;32m-> 8108\u001b[0;31m             \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8109\u001b[0m         )\n\u001b[1;32m   8110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlc/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   8166\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8167\u001b[0m                 joined = merge(\n\u001b[0;32m-> 8168\u001b[0;31m                     \u001b[0mjoined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8169\u001b[0m                 )\n\u001b[1;32m   8170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#trip_keys = list(trip_stop_sequence_dict.keys())[0:10]\n",
    "\n",
    "avg_speed_dfs = []\n",
    "avg_speed_attr_dicts = []\n",
    "errors = 0\n",
    "error_trips = []\n",
    "\n",
    "uncached_trip_keys = []\n",
    "\n",
    "for trip_key in trip_keys:\n",
    "    if trip_key in avg_speed_df_cache:\n",
    "        avg_speed_dfs.append(avg_speed_df_cache[trip_key])\n",
    "        avg_speed_attr_dicts.append(avg_speed_attr_dict_cache[trip_key])\n",
    "    else:\n",
    "        uncached_trip_keys.append(trip_key)\n",
    "\n",
    "#for trip_key in tqdm(uncached_trip_keys):\n",
    "for trip_key in uncached_trip_keys:\n",
    "    #try:\n",
    "    route_id = trip_key.split(',')[0]\n",
    "    trip_id = trip_key.split(',')[1]\n",
    "    sequence_id = trip_key.split(',')[2]\n",
    "    full_key = f'{route_id}_{sequence_id}'\n",
    "    route_mg = route_mgs[route_ids.index(full_key)]\n",
    "\n",
    "    avg_speed_dfs = get_avg_speed_dfs(trip_key, full_key)\n",
    "    avg_speed_attr_dict = get_avg_speed_attr_dict(avg_speed_dfs, route_mg)\n",
    "\n",
    "    avg_speed_dfs.append(avg_speed_df)\n",
    "    avg_speed_attr_dicts.append(avg_speed_attr_dict)\n",
    "\n",
    "    avg_speed_df_cache[trip_key] = avg_speed_df\n",
    "    avg_speed_attr_dict_cache[trip_key] = avg_speed_attr_dict\n",
    "    #except:\n",
    "    #    errors += 1\n",
    "    #    error_trips.append(trip_key)\n",
    "print(f'{len(trip_keys) - errors}/{len(trip_keys)}')\n",
    "display(error_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_speed_attr_dict = {}\n",
    "for attr_dict in avg_speed_attr_dicts:\n",
    "    for key, value in attr_dict.items():\n",
    "        if key not in avg_speed_attr_dict:\n",
    "            avg_speed_attr_dict[key] = {}\n",
    "        for hour_key in value.keys():\n",
    "            if hour_key not in avg_speed_attr_dict[key]:\n",
    "                avg_speed_attr_dict[key][hour_key] = []\n",
    "                avg_speed_attr_dict[key][hour_key] += value[hour_key]\n",
    "        \n",
    "for key, value in avg_speed_attr_dict.items():\n",
    "    for hour_key in value.keys():\n",
    "        avg_speed_attr_dict[key][hour_key] = np.mean(value[hour_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_routes_mg = route_mgs[0]\n",
    "\n",
    "for i, route_mg in enumerate(route_mgs[1:]):\n",
    "    all_routes_mg = nx.compose(all_routes_mg, route_mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_edge_attributes(all_routes_mg, avg_speed_attr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_gdf = graph_to_node_gdf(all_routes_mg)\n",
    "all_edges_gdf = graph_to_edge_gdf(all_routes_mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame({}, geometry=[Point(-73.93606, 40.82071), Point(-73.93536, 40.82177)], crs=CRS_LATLON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(50, 50))\n",
    "all_edges_gdf.plot(ax=ax, color='#333', zorder=1)\n",
    "all_edges_gdf.plot(ax=ax, column='speeds_2', cmap='RdBu', zorder=2, linewidth=3, legend=True)\n",
    "gdf.plot(ax=ax, markersize=50, color='#000', zorder=5)\n",
    "ax.set_facecolor('#777')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(trip_stop_sequence_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(f'{EXPORTS_DIR}/pkl/avg_speed_attr_dict.pkl', 'wb')\n",
    "pickle.dump(avg_speed_attr_dict, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-flashing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
